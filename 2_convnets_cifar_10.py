# -*- coding: utf-8 -*-
"""2 ConvNETS cifar-10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WhML1e6Lvm290WYSUxxyAn9MMOtLYoY7
"""

import pickle
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
from statistics import mean

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

from google.colab import drive
drive.mount('/content/drive')

#Hyper-parameters
NUM_EPOCHS=50
BATCH_SIZE=64
LEARNING_RATE=1e-4

transform= transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])

#Unpickle the Cifar Dataset
def unpickled_file(file_path):
  with open(file_path, 'rb') as fo:
    dict = pickle.load(fo, encoding='latin-1')
  return dict

train_batch_1 = unpickled_file('/content/drive/MyDrive/cifar_10_dataset/data_batch_1')
train_batch_2 = unpickled_file('/content/drive/MyDrive/cifar_10_dataset/data_batch_2')
train_batch_3 = unpickled_file('/content/drive/MyDrive/cifar_10_dataset/data_batch_3')
train_batch_4 = unpickled_file('/content/drive/MyDrive/cifar_10_dataset/data_batch_4')
train_batch_5 = unpickled_file('/content/drive/MyDrive/cifar_10_dataset/data_batch_5')
test_batch = unpickled_file('/content/drive/MyDrive/cifar_10_dataset/test_batch')

train_images = np.concatenate([train_batch_1['data'], train_batch_2['data'], train_batch_3['data'],
                          train_batch_4['data']])
train_labels = np.concatenate([train_batch_1['labels'], train_batch_2['labels'], train_batch_3['labels'],
                          train_batch_4['labels']])

val_images = train_batch_5['data']
val_labels = train_batch_5['labels']

test_images = test_batch['data']
test_labels= test_batch['labels']

train_labels[3:10]

#create a Dataset class for the dataloader object to load the batch dataset.
class CifarDataset(torch.utils.data.Dataset):
  def __init__(self, images, labels, transform=transform):
    super(CifarDataset).__init__()
    self.images = images.astype(np.float32)
    self.labels = labels
    self.lenght = images.shape[0]
    self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])

  def __getitem__ (self, idx):
    return self.images[idx], self.labels[idx]

  def __len__ (self):
    return self.lenght

#Instance (object) of the CifarDataset subclass
train_dataset = CifarDataset(train_images, train_labels)
val_dataset = CifarDataset(val_images, val_labels)
test_dataset = CifarDataset(test_images, test_labels)

train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = torch.utils.data.DataLoader(dataset =val_dataset, batch_size=BATCH_SIZE, shuffle=False)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)

examples = iter(train_loader)
samples, labels = next(examples)
print(samples.shape, labels.shape)

class ConvNets(nn.Module):
  def __init__(self):
    super(ConvNets, self).__init__()
    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride = 1, padding=1)
    self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride = 1, padding=1)
    self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride = 1, padding=1)
    self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride = 1, padding=1)
    self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride = 1, padding=1)
    self.pool = nn.MaxPool2d(2,2)

    self.batch_norm1 = nn.BatchNorm2d(32)
    self.batch_norm2 = nn.BatchNorm2d(64)
    self.batch_norm3 = nn.BatchNorm2d(128)
    self.batch_norm4 = nn.BatchNorm2d(128)
    self.batch_norm5 = nn.BatchNorm2d(256)
    self.batch_norm6 = nn.BatchNorm2d(256)

    self.dropout1 = nn.Dropout2d(p = 0.1)
    self.dropout2 = nn.Dropout2d(p = 0.1)
    self.dropout3 = nn.Dropout2d(p = 0.1)
    self.dropout4 = nn.Dropout2d(p = 0.1)
    self.dropout5 = nn.Dropout2d(p = 0.1)
    self.dropout6 = nn.Dropout2d(p = 0.1)

    self.fc1 = nn.Linear(256*4*4, 1024)
    self.fc2 = nn.Linear(1024, 512)
    self.fc3 = nn.Linear(512, 10)

  def forward(self, x):
    x = self.dropout1(F.relu(self.batch_norm1(self.conv1(x))))
    x = self.pool(self.dropout2(F.relu(self.batch_norm2(self.conv2(x)))))
    x = self.dropout3(F.relu(self.batch_norm3(self.conv3(x))))
    x = self.pool(self.dropout4(F.relu(self.batch_norm4(self.conv4(x)))))
    x = self.dropout5(F.relu(self.batch_norm5(self.conv5(x))))
    x = self.pool(self.dropout6(F.relu(self.batch_norm6(self.conv6(x)))))
    x = x.view(-1, 256*4*4)
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = self.fc3(x)
    return x

model = ConvNets().to(DEVICE)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)

n_total_steps = int(len(train_dataset)/BATCH_SIZE) # No of training iteration per epoch.
for epoch in range(NUM_EPOCHS):
  for i, (images, labels) in enumerate (train_loader):
    images = images.reshape(-1, 3, 32, 32).to(DEVICE)
    labels = labels.to(DEVICE)

    outputs = model(images)
    loss = criterion(outputs, labels)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (i+1) % 100 == 0:
      model.eval()
      with torch.no_grad():
        val_losses = []
        for val_images, val_labels in val_loader:
          val_images = val_images.reshape(-1, 3, 32, 32).to(DEVICE)
          val_labels = val_labels.to(DEVICE)
          preds = model(val_images)
          error = criterion(preds, val_labels)
          val_losses.append(error.item())

          print(f"Epoch[{epoch+1}/{NUM_EPOCHS}], Step[{i+1}/{n_total_steps}], Training Loss:{loss.item():.4f}, Validation_Loss: {mean(val_losses):.4f}")
        model.train()

model.eval()
with torch.no_grad():
  n_correct = 0
  n_samples = 0
  for test_images, test_labels in test_loader:
    test_images = test_images.reshape(-1, 3, 32, 32).to(DEVICE)
    test_labels = test_labels.to(DEVICE)
    outputs = model(test_images)
    _, pred = torch.max(outputs, 1)
    n_samples += test_labels.shape[0]
    n_correct += (pred == test_labels).sum().item()
  model_accuracy = 100* (n_correct/n_samples)

  print(f'Test Accuracy = {model_accuracy}')